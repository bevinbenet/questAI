{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94452cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import google.generativeai as palm\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52c00c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "palm.configure(api_key='AIzaSyAJxuYgNNxKpnbbxjQp0RRS1kFrbUGNK-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25df42a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m models \u001b[38;5;241m=\u001b[39m [m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m palm\u001b[38;5;241m.\u001b[39mlist_models() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerateText\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m m\u001b[38;5;241m.\u001b[39msupported_generation_methods]\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "models = [m for m in palm.list_models() if 'generateText' in m.supported_generation_methods]\n",
    "model = models[1].name\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36bf694c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Section 1: Questions on Chapter 1 of the textbook**\n",
      "\n",
      "1. What is the difference between a hypothesis and a theory?\n",
      "2. What are the three main types of research methods?\n",
      "3. What are the steps of the scientific method?\n",
      "4. What are some of the ethical issues that researchers face?\n",
      "5. How can you evaluate the quality of a research study?\n",
      "\n",
      "**Section 2: Questions on Chapter 2 of the textbook**\n",
      "\n",
      "1. What are the different types of variables?\n",
      "2. How do you measure a variable?\n",
      "3. What are the different types of scales of measurement?\n",
      "4. What are some of the common problems with measurement?\n",
      "5. How can you improve the quality of your measurements?\n",
      "\n",
      "**Section 3: Questions on Chapter 3 of the textbook**\n",
      "\n",
      "1. What is a population and a sample?\n",
      "2. How do you select a sample?\n",
      "3. What are the different types of sampling methods?\n",
      "4. What are some of the problems with sampling?\n",
      "5. How can you improve the quality of your sample?\n"
     ]
    }
   ],
   "source": [
    "section = 0\n",
    "textbook = \"\"\"        \"\"\"\n",
    "\n",
    "question = \"\"\"Generate a 3 sections of questions,  using \"+textbook+\" with \"+section+\" section. Each section should have 5 questions and no need for answers. Also give just the questions with no other text\"\"\"\n",
    "prompt = question\n",
    "\n",
    "\n",
    "completion1 = palm.generate_text(\n",
    "    model=model,\n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    # The maximum length of the response\n",
    "    max_output_tokens=800,\n",
    ")\n",
    "\n",
    "print(completion1.result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4c2436",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392c53dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "questAI",
   "language": "python",
   "name": "questai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
